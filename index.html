<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>optical flow</title>
	<style>
		html,
		body {
			height: 100%;
		}

		video {
			height: 100%;
			width: 100%;
		}

		canvas {
			height: 100%;
			width: 100%;
		}

		#statusText {
			position: absolute;
			top: 24px;
			left: 24px;
			color: white;
			font-weight: bold;
		}

		#featureAlgSelect {
			position: absolute;
			top: 24px;
			right: 24px;
		}
	</style>
</head>

<body>
	<video id="videoInput" class="full-screen hidden" playsinline=true></video>
	<canvas id="canvasOutput" class="full-screen"></canvas>
	<div id="statusText"></div>
	<select id="featureAlgSelect">
	</select>
	<script type="text/javascript">

		const Version = "v1.0";
		const FeatureAlgORB = "ORB";
		const FeatureAlgShiTomasi = "ShiTomasi";

		let maxFeatures = 500;
		let poi = { x: 0, y: 0, size: 200 };
		let framesPerSec = 0;
		let statusErr;

		let featureAlgMap = {};
		featureAlgMap[FeatureAlgShiTomasi] = (function () {
			let none;
			let qualityLevel = 0.2;
			let minDistance = 7;
			let blockSize = 7;
			return {
				id: FeatureAlgShiTomasi,
				get: function (frame, maxFeatures) {
					if (!none) none = new cv.Mat();
					let points = new cv.Mat();
					cv.goodFeaturesToTrack(frame, points, maxFeatures, qualityLevel, minDistance, none, blockSize);
					return points;
				}
			}
		})();
		featureAlgMap[FeatureAlgORB] = (function () {
			return {
				id: FeatureAlgORB,
				get: function (frame, maxFeatures) {
					let orb = new cv.ORB(maxFeatures);
					let keyPoints = new cv.KeyPointVector();
					orb.detect(frame, keyPoints);
					let points = new cv.Mat(maxFeatures, 1, cv.CV_32FC2);
					for (let i = 0; i < keyPoints.size(); i++) {
						let pt = keyPoints.get(i).pt;
						points.floatPtr(i)[0] = pt.x;
						points.floatPtr(i)[1] = pt.y;
					}
					return points;
				}
			}
		})();

		let statusText = document.getElementById("statusText");
		setInterval(function () {
			if (statusErr) {
				statusText.style.color = "black";
				statusText.innerText = Version + " | " + statusErr;
				return;
			}
			statusText.style.color = "black";
			statusText.innerText = Version + " | " + framesPerSec + " fps";
		}, 1000);

		let featureAlgSelect = document.getElementById("featureAlgSelect");
		for (let id in featureAlgMap) {
			var opt = document.createElement("option");
			opt.value = id;
			opt.innerHTML = id;
			featureAlgSelect.appendChild(opt);
		}
		featureAlgSelect.value = FeatureAlgShiTomasi;

		let video = document.getElementById("videoInput");
		video.width = window.innerWidth;
		video.height = window.innerHeight;
		video.style.display = "none";

		let canvas = document.getElementById("canvasOutput");
		canvas.addEventListener('mousedown', function (e) {
			const rect = canvas.getBoundingClientRect();
			const x = e.clientX - rect.left;
			const y = e.clientY - rect.top;
			poi.x = Math.max(0, x - poi.size / 2);
			poi.y = Math.max(0, y - poi.size / 2);
		});
		canvas.addEventListener('touchstart', function (e) {
			const rect = canvas.getBoundingClientRect();
			const touch = e.touches[0];
			if (!touch)
				return;
			const x = touch.pageX - rect.left;
			const y = touch.pageY - rect.top;
			poi.x = Math.max(0, x - poi.size / 2);
			poi.y = Math.max(0, y - poi.size / 2);
		});

		let Module = {
			onRuntimeInitialized() {
				navigator.mediaDevices
					.getUserMedia({
						audio: false,
						video: {
							width: { ideal: video.width },
							height: { ideal: video.height },
							facingMode: 'environment'
						},
					})
					.then(function (stream) {
						// init stream, play
						video.srcObject = stream;
						video.play();
						// center POI
						poi.x = video.width / 2 - poi.size / 2;
						poi.y = video.height / 2 - poi.size / 2;
						// run cv
						cvRun();

					}).catch(function (err) {
						if (err.message)
							statusText = err.message;
					});
			}
		};

		function cvRun() {

			let cap = new cv.VideoCapture(video);
			let featureAlg = featureAlgMap[featureAlgSelect.value];

			// lucas kanade params
			let winSize = new cv.Size(15, 15);
			let maxLevel = 3;
			let criteria = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 40, 0.02);

			// random colors
			let color = [];
			let colorRed = [255, 0, 0, 255]; // RGBA
			let colorGreen = [0, 255, 0, 255]; // RGBA
			for (let i = 0; i < maxFeatures; i++) {
				color.push(new cv.Scalar(parseInt(Math.random() * 255), parseInt(Math.random() * 255),
					parseInt(Math.random() * 255), 255));
			}

			// take first frame and find corners in it
			let oldFrame = new cv.Mat(video.height, video.width, cv.CV_8UC4);
			cap.read(oldFrame);
			let oldGray = new cv.Mat();
			cv.cvtColor(oldFrame, oldGray, cv.COLOR_RGB2GRAY);

			// get initial features
			let p0 = featureAlg.get(oldGray, maxFeatures);

			let frame = new cv.Mat(video.height, video.width, cv.CV_8UC4);
			let frameGray = new cv.Mat();
			let p1 = new cv.Mat();
			let st = new cv.Mat();
			let err = new cv.Mat();

			let frameCnt = 0;
			let frameCntStart = 0;
			let frameTsStart = Date.now();
			const FRAME_KEY_POINTS = 60;
			function processVideo() {

				// FPS estimation
				frameCnt++;
				if (frameCnt >= Number.MAX_SAFE_INTEGER)
					frameCnt = 1;
				if (Date.now() - frameTsStart >= 1000) {
					framesPerSec = Math.round(1000 / Math.max(1, (frameCnt - frameCntStart)));
					frameTsStart = Date.now();
					frameCntStart = frameCnt;
				}

				// start processing
				cap.read(frame);
				cv.cvtColor(frame, frameGray, cv.COLOR_RGBA2GRAY);

				// calculate optical flow
				let dx = 0;
				let dy = 0;
				let dd = 0;
				let pyrLKOk = true;
				try {
					cv.calcOpticalFlowPyrLK(
						oldGray, frameGray,
						p0, p1,
						st, err,
						winSize, maxLevel, criteria
					);
				}
				catch (e) {
					pyrLKOk = false;
					console.error(`calcOpticalFlowPyrLK failed`);
				}

				let goodNew = [];
				let goodOld = [];
				if (pyrLKOk) {
					// select good points
					for (let i = 0; i < st.rows; i++) {
						if (st.data[i] === 1) {
							goodNew.push(new cv.Point(p1.data32F[i * 2], p1.data32F[i * 2 + 1]));
							goodOld.push(new cv.Point(p0.data32F[i * 2], p0.data32F[i * 2 + 1]));
						}
					}
					// draw key points
					for (let i = 0; i < goodNew.length; i++) {
						cv.circle(frame, goodNew[i], 4, color[i], -1);
						if (goodOld[i].x >= poi.x && goodOld[i].x <= poi.x + poi.size
							&& goodOld[i].y >= poi.y && goodOld[i].y <= poi.y + poi.size) {
							dx += goodNew[i].x - goodOld[i].x;
							dy += goodNew[i].y - goodOld[i].y
							dd += 1;
						}
					}
				}

				if (dd > 0) {
					dx = dx / dd;
					dy = dy / dd;
					poi.x += dx;
					poi.x += dy;
				}

				cv.rectangle(frame,
					new cv.Point(poi.x, poi.y),
					new cv.Point(poi.x + poi.size, poi.y + poi.size),
					[dd === 0 ? 255 : 0, dd > 0 ? 255 : 0, 0, 255], // RGBA
					5);

				cv.imshow('canvasOutput', frame);

				// update previous frame
				frameGray.copyTo(oldGray);

				// update previous points
				p0.delete(); p0 = null;
				const sameAlg = featureAlg.id === featureAlgSelect.value;
				if (!pyrLKOk || !sameAlg) {
					if (!sameAlg)
						featureAlg = featureAlgMap[featureAlgSelect.value];
					p0 = featureAlg.get(oldGray, maxFeatures);
				}
				else {
					p0 = new cv.Mat(maxFeatures, 1, cv.CV_32FC2);
					for (let i = 0; i < goodNew.length; i++) {
						p0.data32F[i * 2] = goodNew[i].x;
						p0.data32F[i * 2 + 1] = goodNew[i].y;
					}
				}

				// schedule next frame
				requestAnimationFrame(processVideo);
			};

			// schedule the first one.
			setTimeout(processVideo, 0);
		}
	</script>
	<script async src="https://docs.opencv.org/4.6.0/opencv.js" type="text/javascript"></script>
</body>

</html>