<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>OpenCV test</title>
	<style>
		html,
		body {
			width: 100%;
			height: 100%;
		}

		input {
			display: none;
		}

		img {
			display: none;
			position: absolute;
			display: none;
			width: 100%;
			height: 100%;
		}

		video {
			display: none;
			position: absolute;
			height: 100%;
			width: 100%;
		}

		canvas {
			position: absolute;
			height: 100%;
			width: 100%;
		}

		#statusText {
			position: absolute;
			bottom: 24px;
			right: 24px;
			font-weight: bold;
		}

		#demoBar {
			position: absolute;
			top: 24px;
			left: 24px;
		}

		#featureAlgSelect {
			position: absolute;
			top: 24px;
			right: 24px;
		}
	</style>
</head>

<body>
	<img id="imageInput" alt="No Image" />
	<video id="videoInput" playsinline=true></video>
	<canvas id="canvasOutput"></canvas>
	<div id="statusText"></div>
	<div id="demoBar">
		<select id="demoSelect"></select>
		<input type="file" id="imgFileInput" name="file" />
		<input type="file" id="videoFileInput" name="file" />
	</div>
	<select id="featureAlgSelect"></select>
	<script type="text/javascript">

		const Version = "v2";
		const FeatureAlgORB = "ORB";
		const FeatureAlgShiTomasi = "ShiTomasi";
		const DemoCamera = "Camera Demo";
		const DemoVideo = "Video Demo";
		const DemoImage = "Image Demo";

		let cvRunId = 0;
		let maxFeatures = 500;
		let poi = { x: 0, y: 0, size: 200 };
		let framesPerSec = 0;
		let statusErr;

		let featureAlgMap = {};
		featureAlgMap[FeatureAlgShiTomasi] = (function () {
			let none;
			let qualityLevel = 0.2;
			let minDistance = 7;
			let blockSize = 7;
			return {
				id: FeatureAlgShiTomasi,
				get: function (frame, maxFeatures) {
					if (!none) none = new cv.Mat();
					let points = new cv.Mat();
					cv.goodFeaturesToTrack(frame, points, maxFeatures, qualityLevel, minDistance, none, blockSize);
					return points;
				}
			}
		})();
		featureAlgMap[FeatureAlgORB] = (function () {
			return {
				id: FeatureAlgORB,
				get: function (frame, maxFeatures) {
					let orb = new cv.ORB(maxFeatures);
					let keyPoints = new cv.KeyPointVector();
					orb.detect(frame, keyPoints);
					let points = new cv.Mat(maxFeatures, 1, cv.CV_32FC2);
					for (let i = 0; i < keyPoints.size(); i++) {
						let pt = keyPoints.get(i).pt;
						points.floatPtr(i)[0] = pt.x;
						points.floatPtr(i)[1] = pt.y;
					}
					return points;
				}
			}
		})();

		let statusText = document.getElementById("statusText");
		setInterval(function () {
			if (statusErr) {
				statusText.style.color = "black";
				statusText.innerText = Version + " | " + statusErr;
				return;
			}
			// statusText.style.color = "black";
			statusText.innerText = Version + " | " + framesPerSec + " fps";
		}, 1000);

		let demoSelect = document.getElementById("demoSelect");
		for (let id of [DemoImage, DemoVideo, DemoCamera]) {
			var opt = document.createElement("option");
			opt.value = id;
			opt.innerHTML = id;
			demoSelect.appendChild(opt);
		}
		demoSelect.onchange = onDemoChanged;

		let featureAlgSelect = document.getElementById("featureAlgSelect");
		for (let id in featureAlgMap) {
			var opt = document.createElement("option");
			opt.value = id;
			opt.innerHTML = id;
			featureAlgSelect.appendChild(opt);
		}
		featureAlgSelect.value = FeatureAlgShiTomasi;

		let image = document.getElementById("imageInput");
		image.onload = function() {
			if (demoSelect.value === DemoImage)
				cvRun(false);
		};

		let video = document.getElementById("videoInput");
		video.style.display = "none";

		let imgFileInput = document.getElementById("imgFileInput");
		imgFileInput.addEventListener("change", onDemoChanged, false);

		let videoFileInput = document.getElementById("videoFileInput");
		videoFileInput.addEventListener("change", onDemoChanged, false);

		let canvas = document.getElementById("canvasOutput");
		canvas.addEventListener('mousedown', function (e) {
			const rect = canvas.getBoundingClientRect();
			const x = e.clientX - rect.left;
			const y = e.clientY - rect.top;
			poi.x = Math.max(0, x - poi.size / 2);
			poi.y = Math.max(0, y - poi.size / 2);
		});
		canvas.addEventListener('touchstart', function (e) {
			const rect = canvas.getBoundingClientRect();
			const touch = e.touches[0];
			if (!touch)
				return;
			const x = touch.pageX - rect.left;
			const y = touch.pageY - rect.top;
			poi.x = Math.max(0, x - poi.size / 2);
			poi.y = Math.max(0, y - poi.size / 2);
		});

		let Module = {
			onRuntimeInitialized() {
				onDemoChanged();
			}
		};

		function onDemoChanged() {
	
			const demoId = demoSelect.value;

			cvRunId++;
			if (video.srcObject) {
				video.srcObject.getTracks().forEach(track => {
					track.stop();
					video.srcObject.removeTrack(track);
				});
				video.srcObject = null;
				video.pause();
				video.removeAttribute('src');
				video.load();
			}

			for (let element of [video, canvas, image]) {
				element.width = window.innerWidth;
				element.height = window.innerHeight;
			}
			for (let element of [imgFileInput, videoFileInput]) {
				element.style.display = "none";
			}

			if (demoId === DemoCamera) {
				navigator.mediaDevices
					.getUserMedia({
						audio: false,
						video: {
							width: { ideal: video.width },
							height: { ideal: video.height },
							facingMode: 'environment'
						}
					})
					.then(function (stream) {
						video.srcObject = stream;
						video.play();
						cvRun(true);
					}).catch(function (err) {
						if (err.message)
							statusText = err.message;
					});
				return;
			}

			if (demoId === DemoImage) {
				imgFileInput.style.display = "inline";
				if (imgFileInput.files && imgFileInput.files.length) {
					image.src = URL.createObjectURL(imgFileInput.files[0]);
					cvRun(false);
				}
				return;
			}

			if (demoId === DemoVideo) {
				videoFileInput.style.display = "inline";
				if (videoFileInput.files && videoFileInput.files.length) {
					video.src = URL.createObjectURL(videoFileInput.files[0]);
					video.load();
					video.play();
					cvRun(true);
				}
			}
		}

		function cvRun(isVideo) {

			cvRunId++;
			const currentRunId = cvRunId;
			const frameWidth = window.innerWidth;
			const frameHeight = window.innerHeight;

			// center POI
			poi.x = canvas.width / 2 - poi.size / 2;
			poi.y = canvas.height / 2 - poi.size / 2;

			let cap = isVideo ? new cv.VideoCapture(video) : undefined;
			let featureAlg = featureAlgMap[featureAlgSelect.value];

			// lucas kanade params
			let winSize = new cv.Size(15, 15);
			let maxLevel = 3;
			let criteria = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 40, 0.02);

			// random colors
			let color = [];
			let colorRed = [255, 0, 0, 255]; // RGBA
			let colorGreen = [0, 255, 0, 255]; // RGBA
			for (let i = 0; i < maxFeatures; i++) {
				color.push(new cv.Scalar(parseInt(Math.random() * 255), parseInt(Math.random() * 255),
					parseInt(Math.random() * 255), 255));
			}

			// take first frame and find corners in it
			let oldFrame = new cv.Mat(frameHeight, frameWidth, cv.CV_8UC4);
			if (isVideo)
				cap.read(oldFrame);
			else {
				let tmpMat = cv.imread(image);
				tmpMat.copyTo(oldFrame);
				tmpMat.delete();
			}
			let oldGray = new cv.Mat();
			cv.cvtColor(oldFrame, oldGray, cv.COLOR_RGB2GRAY);

			// get initial features
			let p0 = featureAlg.get(oldGray, maxFeatures);

			let frame = new cv.Mat(frameHeight, frameWidth, cv.CV_8UC4);
			let frameGray = new cv.Mat();
			let p1 = new cv.Mat();
			let st = new cv.Mat();
			let err = new cv.Mat();

			let frameCnt = 0;
			let frameCntStart = 0;
			let frameTsStart = Date.now();
			const FRAME_KEY_POINTS = 60;
			function processVideo() {

				if (currentRunId !== cvRunId) {
					// clean resources
					if (oldFrame) oldFrame.delete();
					if (oldGray) oldGray.delete();
					if (frame) frame.delete();
					if (frameGray) frameGray.delete();
					// fill with white
					if (canvas && canvas.width && canvas.height) {
						let ctx = canvas.getContext("2d");
						ctx.fillStyle = "white";
						ctx.fillRect(0, 0, canvas.width, canvas.height);
					}
					return;
				}

				// FPS estimation
				frameCnt++;
				if (frameCnt >= Number.MAX_SAFE_INTEGER)
					frameCnt = 1;
				if (Date.now() - frameTsStart >= 1000) {
					framesPerSec = Math.round(1000 / Math.max(1, (frameCnt - frameCntStart)));
					frameTsStart = Date.now();
					frameCntStart = frameCnt;
				}

				// start processing
				if (isVideo)
					cap.read(frame);
				else {
					let tmpMat = cv.imread(image);
					tmpMat.copyTo(frame);
					tmpMat.delete();
				}
				cv.cvtColor(frame, frameGray, cv.COLOR_RGBA2GRAY);

				// calculate optical flow
				let dx = 0;
				let dy = 0;
				let dd = 0;
				let pyrLKOk = true;
				try {
					cv.calcOpticalFlowPyrLK(
						oldGray, frameGray,
						p0, p1,
						st, err,
						winSize, maxLevel, criteria
					);
				}
				catch (e) {
					pyrLKOk = false;
					console.error(`calcOpticalFlowPyrLK failed`);
				}

				let goodNew = [];
				let goodOld = [];
				if (pyrLKOk) {
					// select good points
					for (let i = 0; i < st.rows; i++) {
						if (st.data[i] === 1) {
							goodNew.push(new cv.Point(p1.data32F[i * 2], p1.data32F[i * 2 + 1]));
							goodOld.push(new cv.Point(p0.data32F[i * 2], p0.data32F[i * 2 + 1]));
						}
					}
					// draw key points
					for (let i = 0; i < goodNew.length; i++) {
						cv.circle(frame, goodNew[i], 4, color[i], -1);
						if (goodOld[i].x >= poi.x && goodOld[i].x <= poi.x + poi.size
							&& goodOld[i].y >= poi.y && goodOld[i].y <= poi.y + poi.size) {
							dx += goodNew[i].x - goodOld[i].x;
							dy += goodNew[i].y - goodOld[i].y
							dd += 1;
						}
					}
				}

				if (dd > 0) {
					dx = dx / dd;
					dy = dy / dd;
					poi.x += dx;
					poi.x += dy;
				}

				cv.rectangle(frame,
					new cv.Point(poi.x, poi.y),
					new cv.Point(poi.x + poi.size, poi.y + poi.size),
					[dd === 0 ? 255 : 0, dd > 0 ? 255 : 0, 0, 255], // RGBA
					5);

				cv.imshow('canvasOutput', frame);

				// update previous frame
				frameGray.copyTo(oldGray);

				// update previous points
				p0.delete(); p0 = null;
				const sameAlg = featureAlg.id === featureAlgSelect.value;
				if (!pyrLKOk || !sameAlg) {
					if (!sameAlg)
						featureAlg = featureAlgMap[featureAlgSelect.value];
					p0 = featureAlg.get(oldGray, maxFeatures);
				}
				else {
					p0 = new cv.Mat(maxFeatures, 1, cv.CV_32FC2);
					for (let i = 0; i < goodNew.length; i++) {
						p0.data32F[i * 2] = goodNew[i].x;
						p0.data32F[i * 2 + 1] = goodNew[i].y;
					}
				}

				// schedule next frame
				requestAnimationFrame(processVideo);
			};

			// schedule the first one.
			setTimeout(processVideo, 0);
		}
	</script>
	<script async src="https://docs.opencv.org/4.6.0/opencv.js" type="text/javascript"></script>
</body>

</html>