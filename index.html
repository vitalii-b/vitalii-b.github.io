<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>OpenCV test</title>
	<style>
		html,
		body {
			width: 100%;
			height: 100%;
		}

		input {
			display: none;
		}

		img {
			display: none;
			position: absolute;
			display: none;
			width: 100%;
			height: 100%;
		}

		video {
			display: none;
			position: absolute;
			height: 100%;
			width: 100%;
		}

		canvas {
			position: absolute;
			height: 100%;
			width: 100%;
		}

		#statusText {
			position: absolute;
			bottom: 24px;
			right: 24px;
			font-weight: bold;
		}

		#demoBar {
			position: absolute;
			top: 24px;
			left: 24px;
		}

		#featureAlgSelect {
			position: absolute;
			top: 24px;
			right: 24px;
		}
	</style>
</head>

<body>
	<img id="imageInput" alt="No Image" />
	<video id="videoInput" playsinline=true></video>
	<canvas id="canvasOutput"></canvas>
	<div id="statusText"></div>
	<div id="demoBar">
		<select id="demoSelect"></select>
		<input type="file" id="imgFileInput" name="file" />
		<input type="file" id="videoFileInput" name="file" />
	</div>
	<select id="featureAlgSelect"></select>
	<script type="text/javascript">

		const Version = "v2";
		const FeatureAlgORB = "ORB";
		const FeatureAlgShiTomasi = "ShiTomasi";
		const DemoCamera = "Camera Demo";
		const DemoVideo = "Video Demo";
		const DemoImage = "Image Demo";

		let cvRunId = 0;
		let drawFeatures = true;
		let maxFeatures = 100;
		let poiSize = 150;
		let poi = { v: 0, x: 0, y: 0, size: poiSize };
		let framesPerSec = 0;
		let statusErr;

		let featureAlgMap = {};
		featureAlgMap[FeatureAlgShiTomasi] = (function () {
			let none;
			let qualityLevel = 0.2;
			let minDistance = 7;
			let blockSize = 7;
			return {
				id: FeatureAlgShiTomasi,
				get: function (frame, maxFeatures) {
					if (!none) none = new cv.Mat();
					let points = new cv.Mat();
					cv.goodFeaturesToTrack(frame, points, maxFeatures, qualityLevel, minDistance, none, blockSize);
					return points;
				}
			}
		})();
		featureAlgMap[FeatureAlgORB] = (function () {
			return {
				id: FeatureAlgORB,
				get: function (frame, maxFeatures) {
					let orb = new cv.ORB(maxFeatures);
					let keyPoints = new cv.KeyPointVector();
					orb.detect(frame, keyPoints);
					let points = new cv.Mat(maxFeatures, 1, cv.CV_32FC2);
					for (let i = 0; i < keyPoints.size(); i++) {
						let pt = keyPoints.get(i).pt;
						points.floatPtr(i)[0] = pt.x;
						points.floatPtr(i)[1] = pt.y;
					}
					return points;
				}
			}
		})();

		let statusText = document.getElementById("statusText");
		setInterval(function () {
			if (statusErr) {
				statusText.style.color = "black";
				statusText.innerText = Version + " | " + statusErr;
				return;
			}
			// statusText.style.color = "black";
			statusText.innerText = Version + " | " + framesPerSec + " fps";
		}, 1000);

		let demoSelect = document.getElementById("demoSelect");
		for (let id of [DemoVideo, DemoCamera, DemoImage]) {
			var opt = document.createElement("option");
			opt.value = id;
			opt.innerHTML = id;
			demoSelect.appendChild(opt);
		}
		demoSelect.onchange = onDemoChanged;

		let featureAlgSelect = document.getElementById("featureAlgSelect");
		for (let id in featureAlgMap) {
			var opt = document.createElement("option");
			opt.value = id;
			opt.innerHTML = id;
			featureAlgSelect.appendChild(opt);
		}
		featureAlgSelect.value = FeatureAlgShiTomasi;

		let image = document.getElementById("imageInput");
		image.onload = function() {
			if (demoSelect.value === DemoImage)
				cvRun(false);
		};

		let video = document.getElementById("videoInput");
		video.loop = true;
		video.addEventListener("loadeddata", function() {
			if (demoSelect.value === DemoVideo || demoSelect.value === DemoCamera)
				cvRun(true);
		}, false);
		video.style.display = "none";

		let imgFileInput = document.getElementById("imgFileInput");
		imgFileInput.addEventListener("change", onDemoChanged, false);

		let videoFileInput = document.getElementById("videoFileInput");
		videoFileInput.addEventListener("change", onDemoChanged, false);

		let canvas = document.getElementById("canvasOutput");
		canvas.addEventListener('mousedown', function (e) {
			const rect = canvas.getBoundingClientRect();
			const x = e.clientX - rect.left;
			const y = e.clientY - rect.top;
			poi.v++;
			poi.x = Math.max(0, x - poi.size / 2);
			poi.y = Math.max(0, y - poi.size / 2);
			poi.size = poiSize;
		});
		canvas.addEventListener('touchstart', function (e) {
			const rect = canvas.getBoundingClientRect();
			const touch = e.touches[0];
			if (!touch)
				return;
			const x = touch.pageX - rect.left;
			const y = touch.pageY - rect.top;
			poi.v++;
			poi.x = Math.max(0, x - poi.size / 2);
			poi.y = Math.max(0, y - poi.size / 2);
			poi.size = poiSize;
		});


		let Module = {
			onRuntimeInitialized() {
				onDemoChanged();
			}
		};

		function onDemoChanged() {
	
			const demoId = demoSelect.value;

			cvRunId++;
			if (video.srcObject) {
				video.srcObject.getTracks().forEach(track => {
					track.stop();
					video.srcObject.removeTrack(track);
				});
				video.srcObject = null;
				video.pause();
				video.removeAttribute('src');
				video.load();
			}

			for (let element of [video, canvas, image]) {
				element.width = window.innerWidth;
				element.height = window.innerHeight;
			}
			for (let element of [imgFileInput, videoFileInput]) {
				element.style.display = "none";
			}

			if (demoId === DemoCamera) {
				navigator.mediaDevices
					.getUserMedia({
						audio: false,
						video: {
							width: { ideal: video.width },
							height: { ideal: video.height },
							facingMode: 'environment'
						}
					})
					.then(function (stream) {
						video.srcObject = stream;
						video.play();
					}).catch(function (err) {
						if (err.message)
							statusText = err.message;
					});
				return;
			}

			if (demoId === DemoImage) {
				imgFileInput.style.display = "inline";
				if (imgFileInput.files && imgFileInput.files.length) {
					image.src = URL.createObjectURL(imgFileInput.files[0]);
				}
				return;
			}

			if (demoId === DemoVideo) {
				videoFileInput.style.display = "inline";
				if (videoFileInput.files && videoFileInput.files.length) {
					video.src = URL.createObjectURL(videoFileInput.files[0]);
					video.load();
					video.play();
				}
			}
		}

		function cvRun(isVideo) {

			cvRunId++;
			const currentRunId = cvRunId;
			const frameWidth = window.innerWidth;
			const frameHeight = window.innerHeight;

			// center POI
			poi.x = canvas.width / 2 - poi.size / 2;
			poi.y = canvas.height / 2 - poi.size / 2;
			poi.size = poiSize;

			let cap = isVideo ? new cv.VideoCapture(video) : undefined;
			let featureAlg = featureAlgMap[featureAlgSelect.value];

			// lucas kanade params
			let winSize = new cv.Size(15, 15);
			let maxLevel = 3;
			let criteria = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 40, 0.02);

			// random colors
			let color = [];
			let colorRed = [255, 0, 0, 255]; // RGBA
			let colorGreen = [0, 255, 0, 255]; // RGBA
			for (let i = 0; i < maxFeatures; i++) {
				color.push(new cv.Scalar(parseInt(Math.random() * 255), parseInt(Math.random() * 255),
					parseInt(Math.random() * 255), 255));
			}

			// take first frame and find corners in it
			let oldFrame = new cv.Mat(frameHeight, frameWidth, cv.CV_8UC4);
			if (isVideo)
				cap.read(oldFrame);
			else {
				let tmpMat = cv.imread(image);
				tmpMat.copyTo(oldFrame);
				tmpMat.delete();
			}
			let oldGray = new cv.Mat();
			cv.cvtColor(oldFrame, oldGray, cv.COLOR_RGB2GRAY);

			// get initial features
			let p0 = featureAlg.get(oldGray, maxFeatures);

			let frame = new cv.Mat(frameHeight, frameWidth, cv.CV_8UC4);
			let frameGray = new cv.Mat();
			let p1 = new cv.Mat();
			let st = new cv.Mat();
			let err = new cv.Mat();

			let mask = undefined;
			let poiV = poi.v;
			let videoTs = video.currentTime;

			let frameCnt = 0;
			let frameCntStart = 0;
			let frameTsStart = Date.now();
			const FRAME_KEY_POINTS = 60;
			function processVideo() {

				if (currentRunId !== cvRunId) {
					// clean resources
					if (oldFrame) oldFrame.delete();
					if (oldGray) oldGray.delete();
					if (frame) frame.delete();
					if (frameGray) frameGray.delete();
					if (mask) mask.delete();
					// fill with white
					if (canvas && canvas.width && canvas.height) {
						let ctx = canvas.getContext("2d");
						ctx.fillStyle = "white";
						ctx.fillRect(0, 0, canvas.width, canvas.height);
					}
					return;
				}

				// FPS estimation
				frameCnt++;
				if (frameCnt >= Number.MAX_SAFE_INTEGER)
					frameCnt = 1;
				if (Date.now() - frameTsStart >= 1000) {
					framesPerSec = Math.round(1000 / Math.max(1, (frameCnt - frameCntStart)));
					frameTsStart = Date.now();
					frameCntStart = frameCnt;
				}

				// start processing
				if (isVideo)
					cap.read(frame);
				else {
					let tmpMat = cv.imread(image);
					tmpMat.copyTo(frame);
					tmpMat.delete();
				}
				cv.cvtColor(frame, frameGray, cv.COLOR_RGBA2GRAY);

				// calculate optical flow
				let pyrLKOk = true;
				try {
					cv.calcOpticalFlowPyrLK(
						oldGray, frameGray,
						p0, p1,
						st, err,
						winSize, maxLevel, criteria
					);
				}
				catch (e) {
					pyrLKOk = false;
					console.error(`calcOpticalFlowPyrLK failed`);
				}

				// check video end, poi change
				let resetLK = !pyrLKOk;
				if (isVideo) {
					if (video.currentTime < videoTs)
						resetLK = true;
					videoTs = video.currentTime;
				}
				if (poiV !== poi.v) {
					resetLK = true;
					poiV = poi.v;
				}
				if (resetLK) {
					pyrLKOk = false;
					if (mask) mask.delete();
					mask = null;
				}

				let goodFeatures = 0;
				if (pyrLKOk) {
					// draw key points
					for (let i = 0; i < st.rows; i++) {
						if (st.data[i] === 1) {
							goodFeatures++;
							if (drawFeatures) {
								let pt = new cv.Point(p1.data32F[i * 2], p1.data32F[i * 2 + 1]);
								cv.circle(frame, pt, 3, color[i], -1);
							}
						}
					}
				}

				// calc affine transform
				if (pyrLKOk) {
					let src = new cv.Mat(goodFeatures, 1, cv.CV_32FC2);
					let dst = new cv.Mat(goodFeatures, 1, cv.CV_32FC2); 
					for (let i = 0, j = 0; i < st.rows; i++) {
						if (st.data[i] === 1) {
							src.data32F[j * 2] = p0.data32F[i * 2];
							src.data32F[j * 2 + 1] = p0.data32F[i * 2 + 1];
							dst.data32F[j * 2] = p1.data32F[i * 2];
							dst.data32F[j * 2 + 1] = p1.data32F[i * 2 + 1];
							j++;
						}
					}
					let affine;
					try {
						affine = cv.estimateAffine2D(src, dst);
					}
					catch (e) {
						console.error(`estimateAffine2D failed`);
					}
					src.delete(); dst.delete();

					if (affine) {
						// // opt 1
						// let a = affine.data64F[0];
						// let b = affine.data64F[1];
						// let tx = affine.data64F[2];
						// let c = affine.data64F[3];
						// let d = affine.data64F[4];
						// let ty = affine.data64F[5];
						// let sx = Math.sign(a) * Math.sqrt(a*a + b*b);
						// let sy = Math.sign(d) * Math.sqrt(c*c + d*d);
						// let rotation = Math.atan2(c, d);
						// poi.x = (poi.x + tx) * sx;
						// poi.y = (poi.y + ty) * sy;
						// poi.size = poi.size * ((sx + sy) / 2);
						// cv.rectangle(frame,
						// 	new cv.Point(poi.x, poi.y),
						// 	new cv.Point(poi.x + poi.size, poi.y + poi.size),
						// 	[255, 255, 0, 255], // RGBA
						// 	3);

						// opt 2
						if (!mask) {
							let zeros = new cv.Scalar(0, 0, 0, 255);
							mask = new cv.Mat(frame.rows, frame.cols, frame.type(), zeros);
							cv.rectangle(mask,
								new cv.Point(poi.x, poi.y),
								new cv.Point(poi.x + poi.size, poi.y + poi.size),
								[0, 255, 0, 255], // RGBA
								5);
						}
						else {
							try {
								//cv.transform(mask, mask, affine, mask.size());
								cv.warpAffine(mask, mask, affine, mask.size());
							}
							catch (e) {
								console.log(`warpAffine failed`);
							}
						}
						cv.add(frame, mask, frame);

						affine.delete();
					}
					else {
						if (mask) mask.delete();
					}
				}

				cv.imshow('canvasOutput', frame);

				// update previous frame
				frameGray.copyTo(oldGray);

				p0.delete();
				p0 = featureAlg.get(oldGray, maxFeatures);

				// schedule next frame
				requestAnimationFrame(processVideo);
			};

			// schedule the first one.
			setTimeout(processVideo, 0);
		}
	</script>
	<script async src="https://docs.opencv.org/4.6.0/opencv.js" type="text/javascript"></script>
</body>

</html>